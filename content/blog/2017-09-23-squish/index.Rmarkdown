---
title: Squishing a big bad bug
author: Zhian N. Kamvar
date: '2017-09-17'
slug: squish
categories:
  - R
  - science
tags:
  - poppr
  - bruvo
  - algorithms
images:
 - img/banners/mistake.png
---

```{r setup, echo = FALSE, include = FALSE}
knitr::opts_chunk$set(fig.height = 5, 
                      fig.width = 7, 
                      out.width = "100%", 
                      fig.align = "center", 
                      dpi = 150,
                      warning = FALSE,
                      message = FALSE)
```


```{r echo = FALSE}
birdz <- rep(emo::ji("bird"), 2)
eaglz <- rep(emo::ji("eagle"), 2)
beagz <- c(birdz[1], eaglz[1])
```


```{r echo=FALSE, results='hide'}
requireNamespace("poppr", quietly = TRUE)
# Published data from Bruvo et al 2004 (with extra zeroes)
# 
tg <- structure(c(0L, 0L, 0L, 20L, 20L, 24L, 23L, 26L, 24L, 43L), 
                .Dim = c(2L, 5L), .Dimnames = list(c("1", "2"), NULL))
tg1 <- tg

# Comparison function
amat <- function(a1, a2) 1 - 2^(-abs(a1 - a2))

# Create the Distance Matrix

distmat <- function(allmat){
  n     <- ncol(allmat)
  pairs <- expand.grid(allmat[1, ], allmat[2, ]) 
  mat   <- matrix(apply(pairs, 1, function(x) amat(x[1], x[2])), n, n)
  # Infinite model accounted for here
  mat[allmat[1, ] == "0", ] <- 1
  mat[, allmat[2, ] == "0"] <- 1
  dimnames(mat) <- list(allmat[1, ], allmat[2, ])
  mat
}
# Calculate distance between two samples
brvo <- function(allmat){
  n     <- ncol(allmat)
  rows  <- seq(n)
  mat   <- distmat(allmat)
  perms <- matrix(.Call("permuto", n, PACKAGE = "poppr") + 1, nrow = n) 
  walks <- apply(perms, 2, function(i) mean(mat[matrix(c(rows, i), ncol = 2)]))
  min(walks)
}

badd <- function(dat, repls, zeroes = 1, zlocat, old_model = FALSE){
  combs   <- lapply(repls, function(i) dat[zeroes, !zlocat]) 
  combs   <- do.call(expand.grid, combs)
  combs   <- t(apply(combs, 1, sort))
  combs   <- if (old_model) unique(combs) else combs
  combs   <- if (nrow(combs) == 1) t(combs) else combs
  addlist <- vector(mode = "list", length = nrow(combs))
  for (i in seq(nrow(combs))){
    addlist[[i]] <- dat
    addlist[[i]][zeroes, zlocat] <- combs[i, ]
  }
  return(addlist)
}

bloss <- function(dat, repls, zeroes = 1, nzeroes = rowSums(dat == 0), old_model = FALSE){
  donor    <- which.min(nzeroes)
  combs    <- lapply(repls, function(i) dat[donor, ]) 
  combs    <- do.call(expand.grid, combs)
  combs    <- t(apply(combs, 1, sort))
  combs    <- if (old_model) unique(combs) else combs
  combs    <- if (nrow(combs) == 1) t(combs) else combs
  losslist <- vector(mode = "list", length = nrow(combs))
  for (i in seq(nrow(combs))){
    losslist[[i]] <- dat
    losslist[[i]][zeroes, repls] <- combs[i, ]
  }
  return(losslist)
}

# Calculate distance between two samples with different models
Rbruvo <- function(dat, add = TRUE, loss = TRUE, old_model = FALSE){
  dat <- t(apply(dat, 1, sort))
  dat <- dat[, colSums(dat, na.rm = TRUE) > 0]
  if (!add & !loss){
    return(brvo(dat))
  } 
  nzeroes <- rowSums(dat == 0)
  zeroes  <- which.max(nzeroes)
  repls   <- seq(nzeroes[zeroes])
  zlocat  <- dat[zeroes, ] == 0
  mloss   <- 0
  madd    <- 0
  if (loss){
    losslist <- bloss(dat, repls, zeroes, nzeroes, old_model)
    mloss    <- sum(vapply(losslist, brvo, numeric(1)))/length(losslist)
  }
  if (add){
    addlist <- badd(dat, repls, zeroes, zlocat, old_model)
    madd    <- sum(vapply(addlist, brvo, numeric(1)))/length(addlist)
  }
  
  (mloss + madd)/(sum(c(mloss, madd) > 0L))
}

```

As I was preparing to push a [new version of *poppr*](https://github.com/grunwaldlab/poppr/releases/tag/v.2.5.0) to CRAN 
, this tweet (appropriately) came across my feed:

`r blogdown::shortcode("tweet 906959242724179968")`

The reason I was updating *poppr* was to fix a mistake I had made a few years ago.
In the realm of scientific mistakes on a scale of [hapliod] to [arsenic], I would say this probably falls somewhere on the lower end, but still significant enough that I felt I should blog about it ¯\\\_(ツ)\_/¯. 

My Mistake
----------

Mistakes in scientific software happen all the time, [which is why we have automated testing](http://ivory.idyll.org/blog/automated-testing-and-research-software.html). 
Usually, these kind of bugs are things like [simple logical errors](https://github.com/grunwaldlab/poppr/issues/5) that can easily be fixed by changing a single character.
Unfortunately, the [issue I was fixing](https://github.com/grunwaldlab/poppr/issues/139) was not so easily fixed. 
In short, in my assumptions about how to calculate [Bruvo's genetic distance](https://www.ncbi.nlm.nih.gov/pubmed/15189230) for polyploid genotypes with multiple ambiguous alleles was incorrect (a detailed explanation of how Bruvo's distance works can be found below for those interested). 
Without going into too much detail, at the heart of the error, I had fallen for a common statistical misconception of independent probabilities. Consider the following question:

> **If you have two fair coins and flip both of them, what is the most likely scenario?**
> 
> (a) both are heads (`r paste(birdz, col = " ")`)
> (b) both are tails (`r paste(eaglz, col = " ")`)
> (c) one heads and one tails (`r paste(beagz, col = " ")`)
> (d) all are equally likely (`r paste(birdz, col = " ")`) == (`r paste(beagz, col = " ")`) == (`r paste(eaglz, col = " ")`)

When I first saw this question, my immediate answer was **d**, but if I had paid attention in statistics class, or even remembered what the [dots on my Settlers of Catan board](https://cs.stanford.edu/people/nick/settlers/DiceOddsSettlers.html) meant, I would have answered **c**.

Embarassingly, I had assumed that the possible outcomes were unordered (the number of which is dictated by the [multiset coefficient](https://en.wikipedia.org/wiki/Multiset#Counting_multisets)),

| outcome                       | probability |
| ----------------------------- | -----------:|
| (`r paste(birdz, col = " ")`) |          *p*|
| (`r paste(beagz, col = " ")`) |          *p*|
| (`r paste(eaglz, col = " ")`) |          *p*|


as opposed to ordered (of which there is an exponential number of possible outcomes).

| outcome                       | probability |
| ----------------------------- | -----------:|
| (`r paste(birdz, col = " ")`) |         *p* |
| (`r paste(beagz, col = " ")`) |         2*p*|
| (`r paste(eaglz, col = " ")`) |         *p* |


Of course, both (`r paste(beagz, col = " ")`) and (`r paste(rev(beagz), col = " ")`) can occur with equal frequency. 
You can see this with a little simulation:


```{r coins, fig.width = 4, fig.height = 4, fig.align="center"}
# Function to flip a coin N times
flip   <- function(n) sample(c(1, 0), n, replace = TRUE)
# Flipping two coins 1000 times each
n      <- 1000
set.seed(2017-09-23)
trials <- replicate(2, flip(n))
colnames(trials) <- c("coin 1", "coin 2")
rownames(trials) <- paste("trial", seq(n))
head(trials)
res        <- table(rowSums(trials))
names(res) <- c("TT", "HT", "HH")
barplot(res, col = "violet")
```

The Problem
------------

The process to calculate Bruvo's distance for polyploids with multiple ambiguous alleles involved taking the average value of the distance over all possible genotypes. 
The problem with my assumption of all possible unordered genotypes was that this fundamentally changed the structure of how I iterated through the possibilities, which meant that I would either have to completely re-write the machinery `r emo::ji("sob")` or find a clever way around it. `r emo::ji("thinking")`

I chose the latter path `r emo::ji("triumph")`

The Solution
-------------

It turns out that you can calculate the number of possible combinations of a given set of items using the [multinomial coefficient](https://en.wikipedia.org/wiki/Multinomial_theorem#Number_of_unique_permutations_of_words):

$$
\frac{n!}{k_1!k_2!...k_m!}
$$

where *n* is the number of items in your set and each *k* represents the number of each unique item. 
Since Bruvo's distance doesn't take order into account when it calculates the distance, it was possible to multiply the distance at a particular allele combination with the multinomial coefficient and use the sum of the multinomial coefficients as the denominator to get the average distance[^1]. 
In terms of the coin flips above, we can see how it would work:

| Replaced alleles              | distance | coefficient |
| ----------------------------- | --------:| -----------:|
| (`r paste(birdz, col = " ")`) |      *a* |         1   |
| (`r paste(beagz, col = " ")`) |      *b* |         2   |
| (`r paste(eaglz, col = " ")`) |      *c* |         1   |

The mean without the coefficient would be (*a*\**b*\**c*/3) whereas the mean with the coefficient would be (*a*\*2*b*\**c*/4).

### Implementation

Because I didn't have to substantially change the architecture of the calculation, I was able to give *poppr* users the ability to compare their data by adding a switch in the internal functions that would turn the coefficient calculation off if desired.
This switch is controlled by the global option: `options(old.bruvo.model = FALSE)`. 
If it's set to `TRUE`, calculation of Bruvo's distance will revert to the old method of unordered alleles. 
By doing this, I was able to avoid adding extra potentially confusing arguments to the functions that use Bruvo's distance while still providing backwards compatibility. `r emo::ji("+1")`

Conclusion
----------

Mistakes in scientific software are commonplace. 
The very [first bug discovered in poppr](https://github.com/grunwaldlab/poppr/issues/1) was discovered in 2014, there have been many more since, and there will be more as time goes on. 
When I find a mistake in *poppr*, I do what I would hope any other developer would do: I fix the mistake `r emo::ji_glue(":bug::hammer:")`, make a note that I fixed it `r emo::ji("memo")`, and write a test to make sure the mistake never happens again `r emo::ji_glue(":computer: :white_check_mark:")`.
If I make a mistake, I own it.
There is no valor in covering it up, making excuses for it, or even fixing it and pretending it never happened.

Unfortunately, in this case, it took me several months from finding the bug to actually fixing it. This is due, in part, to the fact that I'm now only working on *poppr* in my spare time. It was also in part for the fact that it took me so long to even figure out the right terms to google for the multinomial coefficient. In terms of actual coding, I spent a weekend re-learning C and getting everything implemented.

At the end of the day, I figure that if I am open and transparent about how I fix bugs in *poppr*, then my users will hopefully have trust in me and also be comfortable in brining up any unexpected results they find. 

----

Calculation of Bruvo's distance
-------------------------------

Bruvo's distance is used for microsatellite markers assuming a stepwise mutation model. Between any two alleles the distance, $d$, is

$$
d = 1 - 2^{-|x|}
$$

where $x$ is the number of repeat units between the alleles. For example, if you have two alleles, 420 and 428 with a repeat motif of ACAT, then they would represent (ACAT)`$_{105}$` and (ACAT)`$_{107}$`, respectively, which would result in a distance of 0.75.

This gets more complicated when you increase the ploidy, because then you must find the minimum average distance among all the alleles. In practice, this involves creating a matrix of Bruvo's distance for all alleles. So, for example, if you had the following alleles in two tetraploid samples:

```{r, echo = FALSE}
ex <- tg[2:1, -1]
ex[1, ] <- sort(ex[1, ])
ex[2, 1] <- 30
ex[2, ] <- sort(ex[2, ])
rownames(ex) <- c("genotype 2:", "genotype 1:")
knitr::kable(ex[2:1, ])
```

The resulting genotype matrix would look like this:

```{r, echo = FALSE}
knitr::kable(distmat(ex), digits = 4, align = "c")
```

If you take the average of the diagonal, you end up with `r signif(mean(diag(distmat(ex))), 4)`. However, if we switch columns 2 and 3 in the above matrix, we find that the average is `r signif(mean(diag(distmat(ex)[, c(1, 3, 2, 4)])), 4)`. If we were to try all possible combinations of rearranging these columns and calculating the mean of the diagonal, we find that this is the minimum value. Because of this, **order of alleles does not matter when calculating Bruvo's distance.** This fact becomes important in just a little bit. 

### Polyploid problem: partial heterozygotes

Of course, this is assuming that all alleles are known, but the problem with polyploids is that it is often difficult to accurately score genotypes that are only partially heterozygotic, so Bruvo came up with a solution where all possible combinations of the observed alleles are used to fill the missing genotypes as demonstrated in figure 1 of the publication:

![Figure 1 from Bruvo et al. 2004](bruvofig.png){width=100%}

This figure is a bit confusing to look at, but what it's demonstrating is that if you weren't able to score that "30" allele, you would be comparing three alleles against four. To compensate, you could do one of four things:

1. Replace the allele with the three known alleles in that genotype (b)
2. Replace the allele with the four known alleles of the other genotype (c)
3. Replace the allele with infinity (d)
4. Do 1 and 2 and average the results. 

In calculating 1, 2, and 4, you must consider all possible combinations to 
fill the missing allele. Luckily, when you only have one allele missing, all possible combinations amounts to the number of alleles observed. However, when you have more than one ambiguous allelic state, the question becomes, do you consider all possible ordered combinations of alleles, of which there are *n*^*k*^ where *n* is the number of observed alleles and *k*, the number of ambiguous alleles or all possible unordered combinations, of which there are ${n+k-1}\choose{k}$ combinations.

For example, if you were comparing two genotypes:

```{r, echo = FALSE}
ex <- tg[2:1, -1]
ex[1, ] <- sort(ex[1, ])
ex[2, 1:2] <- 0
ex[2, ] <- sort(ex[2, ])
rownames(ex) <- c("genotype 2:", "genotype 1:")
knitr::kable(ex[2:1, ], format.args = list(zero.print = emo::ji("shrug")))
```

you would need some way to replace the two ambiguous alleles (`r emo::ji("shrug")`) from genotype 1. 
If we assume that the extra alleles in genotype 2 are due to a recent genome expansion event (genome addition model), we would replace the ambiguous alleles with the observed alleles in genotype 1. Here are all the unordered combinations:

```{r echo = FALSE, results = "asis"}
  nzeroes <- rowSums(ex == 0)
  zeroes  <- which.max(nzeroes)
  repls   <- seq(nzeroes[zeroes])
  zlocat  <- ex[zeroes, ] == 0
  for (i in badd(ex, repls, zeroes, zlocat, TRUE)){
    print(knitr::kable(i[2:1, ], caption = paste("Distance: ", round(brvo(i), 4))))
  }
```

If we take the average of the three, we get a Bruvo's distance of `r round(Rbruvo(ex, loss = FALSE, old_model = TRUE), 4)`, but if we remember that there are two ordered combinations for the center genotype, we average over four distances to get `r round(Rbruvo(ex, loss = FALSE, old_model = FALSE), 4)`.


[ssr]: https://www.thermofisher.com/us/en/home/life-science/sequencing/fragment-analysis/microsatellite-marker-analysis.html

[hapliod]: https://twitter.com/jrossibarra/status/857259389744316416/
[arsenic]: http://www.slate.com/articles/health_and_science/science/2010/12/this_paper_should_not_have_been_published.html
[^1]: For those who like details, here's the calculation of the [multinomial coefficient](https://github.com/zkamvar/poppr/blob/e724d753dec80355bdf3af0ea78e4e4c37682c3d/src/poppr_distance.c#L795-L842) and here's how [it was implemented in the genome addition model](https://github.com/zkamvar/poppr/blob/e724d753dec80355bdf3af0ea78e4e4c37682c3d/src/poppr_distance.c#L941-L944). 


